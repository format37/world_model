{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env:\n",
    "    \n",
    "    def __init__(self, size):\n",
    "        # init field\n",
    "        self.field = np.zeros((size,size))\n",
    "        i = random.randint(0, self.field.shape[0]-1)\n",
    "        j = random.randint(0, self.field.shape[0]-1)\n",
    "        # put agent to field\n",
    "        self.field[i][j] = 1\n",
    "        # define action map\n",
    "        self.action_map = {\n",
    "            'U':(-1,0),\n",
    "            'D':(+1,0),\n",
    "            'L':(0,-1),\n",
    "            'R':(0,+1)\n",
    "        }\n",
    "        \n",
    "    def move(self, cmd):\n",
    "        i, j = np.where(self.field==1)\n",
    "        i, j = i[0], j[0]\n",
    "        ip, jp = self.action_map[cmd]\n",
    "        ir, jr = i+ip, j+jp\n",
    "        if ir>-1 and ir<self.field.shape[0] and jr>-1 and jr<self.field.shape[0]:\n",
    "            self.field[i+ip][j+jp] = 1\n",
    "            self.field[i][j] = 0\n",
    "        \n",
    "    def plot(self):\n",
    "        print(self.field)\n",
    "        \n",
    "    def actions(self, cmd):\n",
    "        action = np.zeros(4)\n",
    "        action_list = list(self.action_map.keys())\n",
    "        action_id = action_list.index(cmd)\n",
    "        action[action_id] = 1\n",
    "        return action\n",
    "    \n",
    "    def action_column(self, cmd):\n",
    "        field_size = self.field.shape[0]\n",
    "        empty_count = field_size-4 # 4 is constant count of 2-d actions\n",
    "        column = np.append(self.actions(cmd), np.zeros(empty_count))\n",
    "        return np.array(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(size):\n",
    "    X = []\n",
    "    Y = []\n",
    "    env = Env(5)\n",
    "    field_size = env.field.shape[0]\n",
    "    field_q_size = field_size**2\n",
    "    \n",
    "    for i in range(size):\n",
    "        # create new env\n",
    "        env = Env(5)\n",
    "        # get random action\n",
    "        action = random.choice(list(env.action_map.keys()))\n",
    "        # represent action as binary column\n",
    "        column = env.action_column(action)\n",
    "        # join action_column to field at rigth to make NxN+1 sized numpy array\n",
    "        field_augmented = np.concatenate((env.field, column.reshape(1,field_size).T), axis=1)\n",
    "        # add input data example\n",
    "        X.append(field_augmented.reshape(field_size*(field_size+1)))\n",
    "        # make native moving\n",
    "        env.move(action)\n",
    "        # add solving\n",
    "        Y.append(env.field.reshape(field_q_size))\n",
    "        \n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(5*(5+1), 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 5*5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "def train(model, x, y, epochs, batch_size):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, x.shape[0], batch_size):\n",
    "            x_batch = x[i:i+batch_size]\n",
    "            y_batch = y[i:i+batch_size]\n",
    "            x_batch = Variable(torch.from_numpy(x_batch).float())\n",
    "            y_batch = Variable(torch.from_numpy(y_batch).float())\n",
    "            \n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()            \n",
    "            output = model(x_batch)\n",
    "            #print(output.shape, y_batch.shape)\n",
    "            loss = F.mse_loss(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('Epoch: {}\\tLoss: {:.6f}'.format(epoch, loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data\n",
    "x_train, y_train = generate_data(1000000)\n",
    "x_test, y_test = generate_data(100000)\n",
    "\n",
    "# define model\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000000, 30), (1000000, 25))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tLoss: 0.045813\n",
      "Epoch: 1\tLoss: 0.042949\n",
      "Epoch: 2\tLoss: 0.041232\n",
      "Epoch: 3\tLoss: 0.040176\n",
      "Epoch: 4\tLoss: 0.039516\n",
      "Epoch: 5\tLoss: 0.039098\n",
      "Epoch: 6\tLoss: 0.038832\n",
      "Epoch: 7\tLoss: 0.038660\n",
      "Epoch: 8\tLoss: 0.038547\n",
      "Epoch: 9\tLoss: 0.038470\n",
      "Epoch: 10\tLoss: 0.038417\n",
      "Epoch: 11\tLoss: 0.038380\n",
      "Epoch: 12\tLoss: 0.038354\n",
      "Epoch: 13\tLoss: 0.038334\n",
      "Epoch: 14\tLoss: 0.038318\n",
      "Epoch: 15\tLoss: 0.038305\n",
      "Epoch: 16\tLoss: 0.038293\n",
      "Epoch: 17\tLoss: 0.038283\n",
      "Epoch: 18\tLoss: 0.038273\n",
      "Epoch: 19\tLoss: 0.038265\n",
      "Epoch: 20\tLoss: 0.038257\n",
      "Epoch: 21\tLoss: 0.038249\n",
      "Epoch: 22\tLoss: 0.038243\n",
      "Epoch: 23\tLoss: 0.038236\n",
      "Epoch: 24\tLoss: 0.038229\n",
      "Epoch: 25\tLoss: 0.038221\n",
      "Epoch: 26\tLoss: 0.038214\n",
      "Epoch: 27\tLoss: 0.038207\n",
      "Epoch: 28\tLoss: 0.038200\n",
      "Epoch: 29\tLoss: 0.038193\n",
      "Epoch: 30\tLoss: 0.038187\n",
      "Epoch: 31\tLoss: 0.038180\n",
      "Epoch: 32\tLoss: 0.038174\n",
      "Epoch: 33\tLoss: 0.038167\n",
      "Epoch: 34\tLoss: 0.038160\n",
      "Epoch: 35\tLoss: 0.038153\n",
      "Epoch: 36\tLoss: 0.038145\n",
      "Epoch: 37\tLoss: 0.038138\n",
      "Epoch: 38\tLoss: 0.038131\n",
      "Epoch: 39\tLoss: 0.038124\n",
      "Epoch: 40\tLoss: 0.038117\n",
      "Epoch: 41\tLoss: 0.038110\n",
      "Epoch: 42\tLoss: 0.038103\n",
      "Epoch: 43\tLoss: 0.038096\n",
      "Epoch: 44\tLoss: 0.038089\n",
      "Epoch: 45\tLoss: 0.038082\n",
      "Epoch: 46\tLoss: 0.038075\n",
      "Epoch: 47\tLoss: 0.038069\n",
      "Epoch: 48\tLoss: 0.038062\n",
      "Epoch: 49\tLoss: 0.038056\n",
      "Epoch: 50\tLoss: 0.038050\n",
      "Epoch: 51\tLoss: 0.038044\n",
      "Epoch: 52\tLoss: 0.038038\n",
      "Epoch: 53\tLoss: 0.038032\n",
      "Epoch: 54\tLoss: 0.038026\n",
      "Epoch: 55\tLoss: 0.038020\n",
      "Epoch: 56\tLoss: 0.038014\n",
      "Epoch: 57\tLoss: 0.038008\n",
      "Epoch: 58\tLoss: 0.038003\n",
      "Epoch: 59\tLoss: 0.037997\n",
      "Epoch: 60\tLoss: 0.037991\n",
      "Epoch: 61\tLoss: 0.037986\n",
      "Epoch: 62\tLoss: 0.037980\n",
      "Epoch: 63\tLoss: 0.037975\n",
      "Epoch: 64\tLoss: 0.037969\n",
      "Epoch: 65\tLoss: 0.037964\n",
      "Epoch: 66\tLoss: 0.037958\n",
      "Epoch: 67\tLoss: 0.037952\n",
      "Epoch: 68\tLoss: 0.037947\n",
      "Epoch: 69\tLoss: 0.037941\n",
      "Epoch: 70\tLoss: 0.037936\n",
      "Epoch: 71\tLoss: 0.037930\n",
      "Epoch: 72\tLoss: 0.037925\n",
      "Epoch: 73\tLoss: 0.037919\n",
      "Epoch: 74\tLoss: 0.037913\n",
      "Epoch: 75\tLoss: 0.037908\n",
      "Epoch: 76\tLoss: 0.037902\n",
      "Epoch: 77\tLoss: 0.037896\n",
      "Epoch: 78\tLoss: 0.037891\n",
      "Epoch: 79\tLoss: 0.037885\n",
      "Epoch: 80\tLoss: 0.037880\n",
      "Epoch: 81\tLoss: 0.037874\n",
      "Epoch: 82\tLoss: 0.037868\n",
      "Epoch: 83\tLoss: 0.037863\n",
      "Epoch: 84\tLoss: 0.037857\n",
      "Epoch: 85\tLoss: 0.037851\n",
      "Epoch: 86\tLoss: 0.037846\n",
      "Epoch: 87\tLoss: 0.037840\n",
      "Epoch: 88\tLoss: 0.037834\n",
      "Epoch: 89\tLoss: 0.037828\n",
      "Epoch: 90\tLoss: 0.037822\n",
      "Epoch: 91\tLoss: 0.037817\n",
      "Epoch: 92\tLoss: 0.037811\n",
      "Epoch: 93\tLoss: 0.037805\n",
      "Epoch: 94\tLoss: 0.037799\n",
      "Epoch: 95\tLoss: 0.037793\n",
      "Epoch: 96\tLoss: 0.037787\n",
      "Epoch: 97\tLoss: 0.037781\n",
      "Epoch: 98\tLoss: 0.037775\n",
      "Epoch: 99\tLoss: 0.037769\n",
      "Epoch: 100\tLoss: 0.037763\n",
      "Epoch: 101\tLoss: 0.037757\n",
      "Epoch: 102\tLoss: 0.037751\n",
      "Epoch: 103\tLoss: 0.037745\n",
      "Epoch: 104\tLoss: 0.037739\n",
      "Epoch: 105\tLoss: 0.037733\n",
      "Epoch: 106\tLoss: 0.037727\n",
      "Epoch: 107\tLoss: 0.037721\n",
      "Epoch: 108\tLoss: 0.037714\n",
      "Epoch: 109\tLoss: 0.037708\n",
      "Epoch: 110\tLoss: 0.037702\n",
      "Epoch: 111\tLoss: 0.037696\n",
      "Epoch: 112\tLoss: 0.037689\n",
      "Epoch: 113\tLoss: 0.037683\n",
      "Epoch: 114\tLoss: 0.037677\n",
      "Epoch: 115\tLoss: 0.037670\n",
      "Epoch: 116\tLoss: 0.037664\n",
      "Epoch: 117\tLoss: 0.037658\n",
      "Epoch: 118\tLoss: 0.037651\n",
      "Epoch: 119\tLoss: 0.037645\n",
      "Epoch: 120\tLoss: 0.037639\n",
      "Epoch: 121\tLoss: 0.037632\n",
      "Epoch: 122\tLoss: 0.037625\n",
      "Epoch: 123\tLoss: 0.037619\n",
      "Epoch: 124\tLoss: 0.037612\n",
      "Epoch: 125\tLoss: 0.037606\n",
      "Epoch: 126\tLoss: 0.037599\n",
      "Epoch: 127\tLoss: 0.037593\n",
      "Epoch: 128\tLoss: 0.037586\n",
      "Epoch: 129\tLoss: 0.037579\n",
      "Epoch: 130\tLoss: 0.037573\n",
      "Epoch: 131\tLoss: 0.037566\n",
      "Epoch: 132\tLoss: 0.037559\n",
      "Epoch: 133\tLoss: 0.037553\n",
      "Epoch: 134\tLoss: 0.037546\n",
      "Epoch: 135\tLoss: 0.037539\n",
      "Epoch: 136\tLoss: 0.037532\n",
      "Epoch: 137\tLoss: 0.037525\n",
      "Epoch: 138\tLoss: 0.037519\n",
      "Epoch: 139\tLoss: 0.037512\n",
      "Epoch: 140\tLoss: 0.037505\n",
      "Epoch: 141\tLoss: 0.037498\n",
      "Epoch: 142\tLoss: 0.037491\n",
      "Epoch: 143\tLoss: 0.037483\n",
      "Epoch: 144\tLoss: 0.037476\n",
      "Epoch: 145\tLoss: 0.037469\n",
      "Epoch: 146\tLoss: 0.037462\n",
      "Epoch: 147\tLoss: 0.037455\n",
      "Epoch: 148\tLoss: 0.037448\n",
      "Epoch: 149\tLoss: 0.037441\n",
      "Epoch: 150\tLoss: 0.037433\n",
      "Epoch: 151\tLoss: 0.037426\n",
      "Epoch: 152\tLoss: 0.037419\n",
      "Epoch: 153\tLoss: 0.037412\n",
      "Epoch: 154\tLoss: 0.037404\n",
      "Epoch: 155\tLoss: 0.037397\n",
      "Epoch: 156\tLoss: 0.037390\n",
      "Epoch: 157\tLoss: 0.037382\n",
      "Epoch: 158\tLoss: 0.037375\n",
      "Epoch: 159\tLoss: 0.037367\n",
      "Epoch: 160\tLoss: 0.037360\n",
      "Epoch: 161\tLoss: 0.037353\n",
      "Epoch: 162\tLoss: 0.037345\n",
      "Epoch: 163\tLoss: 0.037338\n",
      "Epoch: 164\tLoss: 0.037330\n",
      "Epoch: 165\tLoss: 0.037322\n",
      "Epoch: 166\tLoss: 0.037315\n",
      "Epoch: 167\tLoss: 0.037307\n",
      "Epoch: 168\tLoss: 0.037299\n",
      "Epoch: 169\tLoss: 0.037291\n",
      "Epoch: 170\tLoss: 0.037284\n",
      "Epoch: 171\tLoss: 0.037276\n",
      "Epoch: 172\tLoss: 0.037268\n",
      "Epoch: 173\tLoss: 0.037260\n",
      "Epoch: 174\tLoss: 0.037252\n",
      "Epoch: 175\tLoss: 0.037244\n",
      "Epoch: 176\tLoss: 0.037235\n",
      "Epoch: 177\tLoss: 0.037227\n",
      "Epoch: 178\tLoss: 0.037219\n",
      "Epoch: 179\tLoss: 0.037211\n",
      "Epoch: 180\tLoss: 0.037203\n",
      "Epoch: 181\tLoss: 0.037195\n",
      "Epoch: 182\tLoss: 0.037187\n",
      "Epoch: 183\tLoss: 0.037178\n",
      "Epoch: 184\tLoss: 0.037170\n",
      "Epoch: 185\tLoss: 0.037162\n",
      "Epoch: 186\tLoss: 0.037153\n",
      "Epoch: 187\tLoss: 0.037145\n",
      "Epoch: 188\tLoss: 0.037136\n",
      "Epoch: 189\tLoss: 0.037127\n",
      "Epoch: 190\tLoss: 0.037119\n",
      "Epoch: 191\tLoss: 0.037110\n",
      "Epoch: 192\tLoss: 0.037102\n",
      "Epoch: 193\tLoss: 0.037093\n",
      "Epoch: 194\tLoss: 0.037084\n",
      "Epoch: 195\tLoss: 0.037075\n",
      "Epoch: 196\tLoss: 0.037067\n",
      "Epoch: 197\tLoss: 0.037058\n",
      "Epoch: 198\tLoss: 0.037049\n",
      "Epoch: 199\tLoss: 0.037040\n",
      "Epoch: 200\tLoss: 0.037031\n",
      "Epoch: 201\tLoss: 0.037022\n",
      "Epoch: 202\tLoss: 0.037013\n",
      "Epoch: 203\tLoss: 0.037004\n",
      "Epoch: 204\tLoss: 0.036994\n",
      "Epoch: 205\tLoss: 0.036985\n",
      "Epoch: 206\tLoss: 0.036976\n",
      "Epoch: 207\tLoss: 0.036967\n",
      "Epoch: 208\tLoss: 0.036958\n",
      "Epoch: 209\tLoss: 0.036948\n",
      "Epoch: 210\tLoss: 0.036939\n",
      "Epoch: 211\tLoss: 0.036929\n",
      "Epoch: 212\tLoss: 0.036920\n",
      "Epoch: 213\tLoss: 0.036910\n",
      "Epoch: 214\tLoss: 0.036901\n",
      "Epoch: 215\tLoss: 0.036891\n",
      "Epoch: 216\tLoss: 0.036882\n",
      "Epoch: 217\tLoss: 0.036872\n",
      "Epoch: 218\tLoss: 0.036862\n",
      "Epoch: 219\tLoss: 0.036852\n",
      "Epoch: 220\tLoss: 0.036843\n",
      "Epoch: 221\tLoss: 0.036833\n",
      "Epoch: 222\tLoss: 0.036823\n",
      "Epoch: 223\tLoss: 0.036813\n",
      "Epoch: 224\tLoss: 0.036803\n",
      "Epoch: 225\tLoss: 0.036793\n",
      "Epoch: 226\tLoss: 0.036783\n",
      "Epoch: 227\tLoss: 0.036773\n",
      "Epoch: 228\tLoss: 0.036763\n",
      "Epoch: 229\tLoss: 0.036753\n",
      "Epoch: 230\tLoss: 0.036743\n",
      "Epoch: 231\tLoss: 0.036733\n",
      "Epoch: 232\tLoss: 0.036723\n",
      "Epoch: 233\tLoss: 0.036712\n",
      "Epoch: 234\tLoss: 0.036702\n",
      "Epoch: 235\tLoss: 0.036692\n",
      "Epoch: 236\tLoss: 0.036681\n",
      "Epoch: 237\tLoss: 0.036671\n",
      "Epoch: 238\tLoss: 0.036661\n",
      "Epoch: 239\tLoss: 0.036650\n",
      "Epoch: 240\tLoss: 0.036639\n",
      "Epoch: 241\tLoss: 0.036629\n",
      "Epoch: 242\tLoss: 0.036618\n",
      "Epoch: 243\tLoss: 0.036607\n",
      "Epoch: 244\tLoss: 0.036597\n",
      "Epoch: 245\tLoss: 0.036586\n",
      "Epoch: 246\tLoss: 0.036575\n",
      "Epoch: 247\tLoss: 0.036564\n",
      "Epoch: 248\tLoss: 0.036553\n",
      "Epoch: 249\tLoss: 0.036542\n",
      "Epoch: 250\tLoss: 0.036531\n",
      "Epoch: 251\tLoss: 0.036520\n",
      "Epoch: 252\tLoss: 0.036509\n",
      "Epoch: 253\tLoss: 0.036497\n",
      "Epoch: 254\tLoss: 0.036486\n",
      "Epoch: 255\tLoss: 0.036475\n",
      "Epoch: 256\tLoss: 0.036464\n",
      "Epoch: 257\tLoss: 0.036452\n",
      "Epoch: 258\tLoss: 0.036441\n",
      "Epoch: 259\tLoss: 0.036429\n",
      "Epoch: 260\tLoss: 0.036418\n",
      "Epoch: 261\tLoss: 0.036406\n",
      "Epoch: 262\tLoss: 0.036394\n",
      "Epoch: 263\tLoss: 0.036383\n",
      "Epoch: 264\tLoss: 0.036371\n",
      "Epoch: 265\tLoss: 0.036359\n",
      "Epoch: 266\tLoss: 0.036347\n",
      "Epoch: 267\tLoss: 0.036335\n",
      "Epoch: 268\tLoss: 0.036323\n",
      "Epoch: 269\tLoss: 0.036311\n",
      "Epoch: 270\tLoss: 0.036299\n",
      "Epoch: 271\tLoss: 0.036287\n",
      "Epoch: 272\tLoss: 0.036275\n",
      "Epoch: 273\tLoss: 0.036263\n",
      "Epoch: 274\tLoss: 0.036251\n",
      "Epoch: 275\tLoss: 0.036239\n",
      "Epoch: 276\tLoss: 0.036226\n",
      "Epoch: 277\tLoss: 0.036214\n",
      "Epoch: 278\tLoss: 0.036202\n",
      "Epoch: 279\tLoss: 0.036189\n",
      "Epoch: 280\tLoss: 0.036177\n",
      "Epoch: 281\tLoss: 0.036164\n",
      "Epoch: 282\tLoss: 0.036152\n",
      "Epoch: 283\tLoss: 0.036139\n",
      "Epoch: 284\tLoss: 0.036127\n",
      "Epoch: 285\tLoss: 0.036114\n",
      "Epoch: 286\tLoss: 0.036102\n",
      "Epoch: 287\tLoss: 0.036089\n",
      "Epoch: 288\tLoss: 0.036076\n",
      "Epoch: 289\tLoss: 0.036063\n",
      "Epoch: 290\tLoss: 0.036051\n",
      "Epoch: 291\tLoss: 0.036038\n",
      "Epoch: 292\tLoss: 0.036025\n",
      "Epoch: 293\tLoss: 0.036012\n",
      "Epoch: 294\tLoss: 0.035999\n",
      "Epoch: 295\tLoss: 0.035986\n",
      "Epoch: 296\tLoss: 0.035973\n",
      "Epoch: 297\tLoss: 0.035960\n",
      "Epoch: 298\tLoss: 0.035947\n",
      "Epoch: 299\tLoss: 0.035934\n",
      "Epoch: 300\tLoss: 0.035920\n",
      "Epoch: 301\tLoss: 0.035907\n",
      "Epoch: 302\tLoss: 0.035894\n",
      "Epoch: 303\tLoss: 0.035880\n",
      "Epoch: 304\tLoss: 0.035867\n",
      "Epoch: 305\tLoss: 0.035853\n",
      "Epoch: 306\tLoss: 0.035840\n",
      "Epoch: 307\tLoss: 0.035826\n",
      "Epoch: 308\tLoss: 0.035813\n",
      "Epoch: 309\tLoss: 0.035799\n",
      "Epoch: 310\tLoss: 0.035786\n",
      "Epoch: 311\tLoss: 0.035772\n",
      "Epoch: 312\tLoss: 0.035758\n",
      "Epoch: 313\tLoss: 0.035744\n",
      "Epoch: 314\tLoss: 0.035731\n",
      "Epoch: 315\tLoss: 0.035717\n",
      "Epoch: 316\tLoss: 0.035703\n",
      "Epoch: 317\tLoss: 0.035689\n",
      "Epoch: 318\tLoss: 0.035675\n",
      "Epoch: 319\tLoss: 0.035661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 320\tLoss: 0.035647\n",
      "Epoch: 321\tLoss: 0.035633\n",
      "Epoch: 322\tLoss: 0.035618\n",
      "Epoch: 323\tLoss: 0.035604\n",
      "Epoch: 324\tLoss: 0.035590\n",
      "Epoch: 325\tLoss: 0.035576\n",
      "Epoch: 326\tLoss: 0.035562\n",
      "Epoch: 327\tLoss: 0.035547\n",
      "Epoch: 328\tLoss: 0.035533\n",
      "Epoch: 329\tLoss: 0.035518\n",
      "Epoch: 330\tLoss: 0.035504\n",
      "Epoch: 331\tLoss: 0.035489\n",
      "Epoch: 332\tLoss: 0.035474\n",
      "Epoch: 333\tLoss: 0.035460\n",
      "Epoch: 334\tLoss: 0.035445\n",
      "Epoch: 335\tLoss: 0.035430\n",
      "Epoch: 336\tLoss: 0.035415\n",
      "Epoch: 337\tLoss: 0.035400\n",
      "Epoch: 338\tLoss: 0.035385\n",
      "Epoch: 339\tLoss: 0.035370\n",
      "Epoch: 340\tLoss: 0.035355\n",
      "Epoch: 341\tLoss: 0.035340\n",
      "Epoch: 342\tLoss: 0.035325\n",
      "Epoch: 343\tLoss: 0.035310\n",
      "Epoch: 344\tLoss: 0.035295\n",
      "Epoch: 345\tLoss: 0.035280\n",
      "Epoch: 346\tLoss: 0.035265\n",
      "Epoch: 347\tLoss: 0.035250\n",
      "Epoch: 348\tLoss: 0.035235\n",
      "Epoch: 349\tLoss: 0.035219\n",
      "Epoch: 350\tLoss: 0.035204\n",
      "Epoch: 351\tLoss: 0.035189\n",
      "Epoch: 352\tLoss: 0.035173\n",
      "Epoch: 353\tLoss: 0.035158\n",
      "Epoch: 354\tLoss: 0.035142\n",
      "Epoch: 355\tLoss: 0.035127\n",
      "Epoch: 356\tLoss: 0.035111\n",
      "Epoch: 357\tLoss: 0.035096\n",
      "Epoch: 358\tLoss: 0.035080\n",
      "Epoch: 359\tLoss: 0.035064\n",
      "Epoch: 360\tLoss: 0.035049\n",
      "Epoch: 361\tLoss: 0.035033\n",
      "Epoch: 362\tLoss: 0.035017\n",
      "Epoch: 363\tLoss: 0.035002\n",
      "Epoch: 364\tLoss: 0.034986\n",
      "Epoch: 365\tLoss: 0.034970\n",
      "Epoch: 366\tLoss: 0.034954\n",
      "Epoch: 367\tLoss: 0.034938\n",
      "Epoch: 368\tLoss: 0.034922\n",
      "Epoch: 369\tLoss: 0.034906\n",
      "Epoch: 370\tLoss: 0.034890\n",
      "Epoch: 371\tLoss: 0.034874\n",
      "Epoch: 372\tLoss: 0.034858\n",
      "Epoch: 373\tLoss: 0.034842\n",
      "Epoch: 374\tLoss: 0.034826\n",
      "Epoch: 375\tLoss: 0.034810\n",
      "Epoch: 376\tLoss: 0.034793\n",
      "Epoch: 377\tLoss: 0.034777\n",
      "Epoch: 378\tLoss: 0.034761\n",
      "Epoch: 379\tLoss: 0.034744\n",
      "Epoch: 380\tLoss: 0.034728\n",
      "Epoch: 381\tLoss: 0.034712\n",
      "Epoch: 382\tLoss: 0.034696\n",
      "Epoch: 383\tLoss: 0.034680\n",
      "Epoch: 384\tLoss: 0.034663\n",
      "Epoch: 385\tLoss: 0.034647\n",
      "Epoch: 386\tLoss: 0.034631\n",
      "Epoch: 387\tLoss: 0.034615\n",
      "Epoch: 388\tLoss: 0.034598\n",
      "Epoch: 389\tLoss: 0.034582\n",
      "Epoch: 390\tLoss: 0.034566\n",
      "Epoch: 391\tLoss: 0.034550\n",
      "Epoch: 392\tLoss: 0.034533\n",
      "Epoch: 393\tLoss: 0.034517\n",
      "Epoch: 394\tLoss: 0.034500\n",
      "Epoch: 395\tLoss: 0.034484\n",
      "Epoch: 396\tLoss: 0.034468\n",
      "Epoch: 397\tLoss: 0.034451\n",
      "Epoch: 398\tLoss: 0.034435\n",
      "Epoch: 399\tLoss: 0.034419\n",
      "Epoch: 400\tLoss: 0.034402\n",
      "Epoch: 401\tLoss: 0.034386\n",
      "Epoch: 402\tLoss: 0.034369\n",
      "Epoch: 403\tLoss: 0.034353\n",
      "Epoch: 404\tLoss: 0.034336\n",
      "Epoch: 405\tLoss: 0.034320\n",
      "Epoch: 406\tLoss: 0.034303\n",
      "Epoch: 407\tLoss: 0.034286\n",
      "Epoch: 408\tLoss: 0.034270\n",
      "Epoch: 409\tLoss: 0.034253\n",
      "Epoch: 410\tLoss: 0.034237\n",
      "Epoch: 411\tLoss: 0.034220\n",
      "Epoch: 412\tLoss: 0.034203\n",
      "Epoch: 413\tLoss: 0.034187\n",
      "Epoch: 414\tLoss: 0.034170\n",
      "Epoch: 415\tLoss: 0.034153\n",
      "Epoch: 416\tLoss: 0.034136\n",
      "Epoch: 417\tLoss: 0.034120\n",
      "Epoch: 418\tLoss: 0.034103\n",
      "Epoch: 419\tLoss: 0.034086\n",
      "Epoch: 420\tLoss: 0.034069\n",
      "Epoch: 421\tLoss: 0.034052\n",
      "Epoch: 422\tLoss: 0.034036\n",
      "Epoch: 423\tLoss: 0.034019\n",
      "Epoch: 424\tLoss: 0.034002\n",
      "Epoch: 425\tLoss: 0.033985\n",
      "Epoch: 426\tLoss: 0.033969\n",
      "Epoch: 427\tLoss: 0.033952\n",
      "Epoch: 428\tLoss: 0.033935\n",
      "Epoch: 429\tLoss: 0.033918\n",
      "Epoch: 430\tLoss: 0.033902\n",
      "Epoch: 431\tLoss: 0.033885\n",
      "Epoch: 432\tLoss: 0.033868\n",
      "Epoch: 433\tLoss: 0.033851\n",
      "Epoch: 434\tLoss: 0.033834\n",
      "Epoch: 435\tLoss: 0.033818\n",
      "Epoch: 436\tLoss: 0.033801\n",
      "Epoch: 437\tLoss: 0.033784\n",
      "Epoch: 438\tLoss: 0.033767\n",
      "Epoch: 439\tLoss: 0.033751\n",
      "Epoch: 440\tLoss: 0.033734\n",
      "Epoch: 441\tLoss: 0.033717\n",
      "Epoch: 442\tLoss: 0.033701\n",
      "Epoch: 443\tLoss: 0.033684\n",
      "Epoch: 444\tLoss: 0.033667\n",
      "Epoch: 445\tLoss: 0.033651\n",
      "Epoch: 446\tLoss: 0.033634\n",
      "Epoch: 447\tLoss: 0.033617\n",
      "Epoch: 448\tLoss: 0.033600\n",
      "Epoch: 449\tLoss: 0.033584\n",
      "Epoch: 450\tLoss: 0.033567\n",
      "Epoch: 451\tLoss: 0.033550\n",
      "Epoch: 452\tLoss: 0.033534\n",
      "Epoch: 453\tLoss: 0.033517\n",
      "Epoch: 454\tLoss: 0.033500\n",
      "Epoch: 455\tLoss: 0.033483\n",
      "Epoch: 456\tLoss: 0.033467\n",
      "Epoch: 457\tLoss: 0.033450\n",
      "Epoch: 458\tLoss: 0.033433\n",
      "Epoch: 459\tLoss: 0.033416\n",
      "Epoch: 460\tLoss: 0.033399\n",
      "Epoch: 461\tLoss: 0.033383\n",
      "Epoch: 462\tLoss: 0.033366\n",
      "Epoch: 463\tLoss: 0.033349\n",
      "Epoch: 464\tLoss: 0.033332\n",
      "Epoch: 465\tLoss: 0.033315\n",
      "Epoch: 466\tLoss: 0.033299\n",
      "Epoch: 467\tLoss: 0.033282\n",
      "Epoch: 468\tLoss: 0.033265\n",
      "Epoch: 469\tLoss: 0.033248\n",
      "Epoch: 470\tLoss: 0.033232\n",
      "Epoch: 471\tLoss: 0.033215\n",
      "Epoch: 472\tLoss: 0.033198\n",
      "Epoch: 473\tLoss: 0.033181\n",
      "Epoch: 474\tLoss: 0.033165\n",
      "Epoch: 475\tLoss: 0.033148\n",
      "Epoch: 476\tLoss: 0.033131\n",
      "Epoch: 477\tLoss: 0.033114\n",
      "Epoch: 478\tLoss: 0.033097\n",
      "Epoch: 479\tLoss: 0.033080\n",
      "Epoch: 480\tLoss: 0.033064\n",
      "Epoch: 481\tLoss: 0.033047\n",
      "Epoch: 482\tLoss: 0.033030\n",
      "Epoch: 483\tLoss: 0.033013\n",
      "Epoch: 484\tLoss: 0.032996\n",
      "Epoch: 485\tLoss: 0.032979\n",
      "Epoch: 486\tLoss: 0.032962\n",
      "Epoch: 487\tLoss: 0.032946\n",
      "Epoch: 488\tLoss: 0.032929\n",
      "Epoch: 489\tLoss: 0.032912\n",
      "Epoch: 490\tLoss: 0.032895\n",
      "Epoch: 491\tLoss: 0.032878\n",
      "Epoch: 492\tLoss: 0.032861\n",
      "Epoch: 493\tLoss: 0.032844\n",
      "Epoch: 494\tLoss: 0.032827\n",
      "Epoch: 495\tLoss: 0.032810\n",
      "Epoch: 496\tLoss: 0.032793\n",
      "Epoch: 497\tLoss: 0.032776\n",
      "Epoch: 498\tLoss: 0.032758\n",
      "Epoch: 499\tLoss: 0.032741\n",
      "Epoch: 500\tLoss: 0.032724\n",
      "Epoch: 501\tLoss: 0.032707\n",
      "Epoch: 502\tLoss: 0.032690\n",
      "Epoch: 503\tLoss: 0.032673\n",
      "Epoch: 504\tLoss: 0.032656\n",
      "Epoch: 505\tLoss: 0.032638\n",
      "Epoch: 506\tLoss: 0.032621\n",
      "Epoch: 507\tLoss: 0.032604\n",
      "Epoch: 508\tLoss: 0.032586\n",
      "Epoch: 509\tLoss: 0.032569\n",
      "Epoch: 510\tLoss: 0.032552\n",
      "Epoch: 511\tLoss: 0.032535\n",
      "Epoch: 512\tLoss: 0.032518\n",
      "Epoch: 513\tLoss: 0.032501\n",
      "Epoch: 514\tLoss: 0.032484\n",
      "Epoch: 515\tLoss: 0.032466\n",
      "Epoch: 516\tLoss: 0.032448\n",
      "Epoch: 517\tLoss: 0.032431\n",
      "Epoch: 518\tLoss: 0.032414\n",
      "Epoch: 519\tLoss: 0.032397\n",
      "Epoch: 520\tLoss: 0.032380\n",
      "Epoch: 521\tLoss: 0.032363\n",
      "Epoch: 522\tLoss: 0.032346\n",
      "Epoch: 523\tLoss: 0.032329\n",
      "Epoch: 524\tLoss: 0.032313\n",
      "Epoch: 525\tLoss: 0.032296\n",
      "Epoch: 526\tLoss: 0.032280\n",
      "Epoch: 527\tLoss: 0.032264\n",
      "Epoch: 528\tLoss: 0.032247\n",
      "Epoch: 529\tLoss: 0.032231\n",
      "Epoch: 530\tLoss: 0.032215\n",
      "Epoch: 531\tLoss: 0.032199\n",
      "Epoch: 532\tLoss: 0.032182\n",
      "Epoch: 533\tLoss: 0.032166\n",
      "Epoch: 534\tLoss: 0.032150\n",
      "Epoch: 535\tLoss: 0.032134\n",
      "Epoch: 536\tLoss: 0.032118\n",
      "Epoch: 537\tLoss: 0.032101\n",
      "Epoch: 538\tLoss: 0.032085\n",
      "Epoch: 539\tLoss: 0.032069\n",
      "Epoch: 540\tLoss: 0.032053\n",
      "Epoch: 541\tLoss: 0.032037\n",
      "Epoch: 542\tLoss: 0.032020\n",
      "Epoch: 543\tLoss: 0.032004\n",
      "Epoch: 544\tLoss: 0.031988\n",
      "Epoch: 545\tLoss: 0.031972\n",
      "Epoch: 546\tLoss: 0.031956\n",
      "Epoch: 547\tLoss: 0.031940\n",
      "Epoch: 548\tLoss: 0.031925\n",
      "Epoch: 549\tLoss: 0.031909\n",
      "Epoch: 550\tLoss: 0.031893\n",
      "Epoch: 551\tLoss: 0.031876\n",
      "Epoch: 552\tLoss: 0.031860\n",
      "Epoch: 553\tLoss: 0.031845\n",
      "Epoch: 554\tLoss: 0.031829\n",
      "Epoch: 555\tLoss: 0.031813\n",
      "Epoch: 556\tLoss: 0.031797\n",
      "Epoch: 557\tLoss: 0.031782\n",
      "Epoch: 558\tLoss: 0.031766\n",
      "Epoch: 559\tLoss: 0.031750\n",
      "Epoch: 560\tLoss: 0.031734\n",
      "Epoch: 561\tLoss: 0.031719\n",
      "Epoch: 562\tLoss: 0.031703\n",
      "Epoch: 563\tLoss: 0.031687\n",
      "Epoch: 564\tLoss: 0.031671\n",
      "Epoch: 565\tLoss: 0.031656\n",
      "Epoch: 566\tLoss: 0.031640\n",
      "Epoch: 567\tLoss: 0.031624\n",
      "Epoch: 568\tLoss: 0.031608\n",
      "Epoch: 569\tLoss: 0.031592\n",
      "Epoch: 570\tLoss: 0.031577\n",
      "Epoch: 571\tLoss: 0.031561\n",
      "Epoch: 572\tLoss: 0.031546\n",
      "Epoch: 573\tLoss: 0.031530\n",
      "Epoch: 574\tLoss: 0.031515\n",
      "Epoch: 575\tLoss: 0.031499\n",
      "Epoch: 576\tLoss: 0.031484\n",
      "Epoch: 577\tLoss: 0.031469\n",
      "Epoch: 578\tLoss: 0.031453\n",
      "Epoch: 579\tLoss: 0.031438\n",
      "Epoch: 580\tLoss: 0.031423\n",
      "Epoch: 581\tLoss: 0.031407\n",
      "Epoch: 582\tLoss: 0.031392\n",
      "Epoch: 583\tLoss: 0.031377\n",
      "Epoch: 584\tLoss: 0.031362\n",
      "Epoch: 585\tLoss: 0.031347\n",
      "Epoch: 586\tLoss: 0.031332\n",
      "Epoch: 587\tLoss: 0.031317\n",
      "Epoch: 588\tLoss: 0.031301\n",
      "Epoch: 589\tLoss: 0.031286\n",
      "Epoch: 590\tLoss: 0.031271\n",
      "Epoch: 591\tLoss: 0.031256\n",
      "Epoch: 592\tLoss: 0.031241\n",
      "Epoch: 593\tLoss: 0.031226\n",
      "Epoch: 594\tLoss: 0.031211\n",
      "Epoch: 595\tLoss: 0.031196\n",
      "Epoch: 596\tLoss: 0.031181\n",
      "Epoch: 597\tLoss: 0.031166\n",
      "Epoch: 598\tLoss: 0.031151\n",
      "Epoch: 599\tLoss: 0.031136\n",
      "Epoch: 600\tLoss: 0.031122\n",
      "Epoch: 601\tLoss: 0.031107\n",
      "Epoch: 602\tLoss: 0.031092\n",
      "Epoch: 603\tLoss: 0.031077\n",
      "Epoch: 604\tLoss: 0.031062\n",
      "Epoch: 605\tLoss: 0.031047\n",
      "Epoch: 606\tLoss: 0.031033\n",
      "Epoch: 607\tLoss: 0.031018\n",
      "Epoch: 608\tLoss: 0.031003\n",
      "Epoch: 609\tLoss: 0.030988\n",
      "Epoch: 610\tLoss: 0.030973\n",
      "Epoch: 611\tLoss: 0.030959\n",
      "Epoch: 612\tLoss: 0.030944\n",
      "Epoch: 613\tLoss: 0.030929\n",
      "Epoch: 614\tLoss: 0.030915\n",
      "Epoch: 615\tLoss: 0.030900\n",
      "Epoch: 616\tLoss: 0.030885\n",
      "Epoch: 617\tLoss: 0.030870\n",
      "Epoch: 618\tLoss: 0.030856\n",
      "Epoch: 619\tLoss: 0.030841\n",
      "Epoch: 620\tLoss: 0.030826\n",
      "Epoch: 621\tLoss: 0.030811\n",
      "Epoch: 622\tLoss: 0.030796\n",
      "Epoch: 623\tLoss: 0.030782\n",
      "Epoch: 624\tLoss: 0.030767\n",
      "Epoch: 625\tLoss: 0.030752\n",
      "Epoch: 626\tLoss: 0.030737\n",
      "Epoch: 627\tLoss: 0.030722\n",
      "Epoch: 628\tLoss: 0.030707\n",
      "Epoch: 629\tLoss: 0.030692\n",
      "Epoch: 630\tLoss: 0.030678\n",
      "Epoch: 631\tLoss: 0.030663\n",
      "Epoch: 632\tLoss: 0.030648\n",
      "Epoch: 633\tLoss: 0.030633\n",
      "Epoch: 634\tLoss: 0.030619\n",
      "Epoch: 635\tLoss: 0.030604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 636\tLoss: 0.030589\n",
      "Epoch: 637\tLoss: 0.030575\n",
      "Epoch: 638\tLoss: 0.030560\n",
      "Epoch: 639\tLoss: 0.030546\n",
      "Epoch: 640\tLoss: 0.030531\n",
      "Epoch: 641\tLoss: 0.030517\n",
      "Epoch: 642\tLoss: 0.030502\n",
      "Epoch: 643\tLoss: 0.030488\n",
      "Epoch: 644\tLoss: 0.030473\n",
      "Epoch: 645\tLoss: 0.030458\n",
      "Epoch: 646\tLoss: 0.030444\n",
      "Epoch: 647\tLoss: 0.030429\n",
      "Epoch: 648\tLoss: 0.030415\n",
      "Epoch: 649\tLoss: 0.030400\n",
      "Epoch: 650\tLoss: 0.030386\n",
      "Epoch: 651\tLoss: 0.030371\n",
      "Epoch: 652\tLoss: 0.030357\n",
      "Epoch: 653\tLoss: 0.030342\n",
      "Epoch: 654\tLoss: 0.030327\n",
      "Epoch: 655\tLoss: 0.030313\n",
      "Epoch: 656\tLoss: 0.030298\n",
      "Epoch: 657\tLoss: 0.030284\n",
      "Epoch: 658\tLoss: 0.030269\n",
      "Epoch: 659\tLoss: 0.030255\n",
      "Epoch: 660\tLoss: 0.030240\n",
      "Epoch: 661\tLoss: 0.030226\n",
      "Epoch: 662\tLoss: 0.030212\n",
      "Epoch: 663\tLoss: 0.030197\n",
      "Epoch: 664\tLoss: 0.030183\n",
      "Epoch: 665\tLoss: 0.030168\n",
      "Epoch: 666\tLoss: 0.030154\n",
      "Epoch: 667\tLoss: 0.030139\n",
      "Epoch: 668\tLoss: 0.030125\n",
      "Epoch: 669\tLoss: 0.030110\n",
      "Epoch: 670\tLoss: 0.030096\n",
      "Epoch: 671\tLoss: 0.030081\n",
      "Epoch: 672\tLoss: 0.030067\n",
      "Epoch: 673\tLoss: 0.030053\n",
      "Epoch: 674\tLoss: 0.030038\n",
      "Epoch: 675\tLoss: 0.030024\n",
      "Epoch: 676\tLoss: 0.030009\n",
      "Epoch: 677\tLoss: 0.029995\n",
      "Epoch: 678\tLoss: 0.029980\n",
      "Epoch: 679\tLoss: 0.029966\n",
      "Epoch: 680\tLoss: 0.029952\n",
      "Epoch: 681\tLoss: 0.029937\n",
      "Epoch: 682\tLoss: 0.029923\n",
      "Epoch: 683\tLoss: 0.029908\n",
      "Epoch: 684\tLoss: 0.029894\n",
      "Epoch: 685\tLoss: 0.029880\n",
      "Epoch: 686\tLoss: 0.029865\n",
      "Epoch: 687\tLoss: 0.029851\n",
      "Epoch: 688\tLoss: 0.029837\n",
      "Epoch: 689\tLoss: 0.029822\n",
      "Epoch: 690\tLoss: 0.029808\n",
      "Epoch: 691\tLoss: 0.029794\n",
      "Epoch: 692\tLoss: 0.029779\n",
      "Epoch: 693\tLoss: 0.029765\n",
      "Epoch: 694\tLoss: 0.029751\n",
      "Epoch: 695\tLoss: 0.029736\n",
      "Epoch: 696\tLoss: 0.029722\n",
      "Epoch: 697\tLoss: 0.029708\n",
      "Epoch: 698\tLoss: 0.029693\n",
      "Epoch: 699\tLoss: 0.029679\n",
      "Epoch: 700\tLoss: 0.029665\n",
      "Epoch: 701\tLoss: 0.029650\n",
      "Epoch: 702\tLoss: 0.029636\n",
      "Epoch: 703\tLoss: 0.029622\n",
      "Epoch: 704\tLoss: 0.029607\n",
      "Epoch: 705\tLoss: 0.029593\n",
      "Epoch: 706\tLoss: 0.029579\n",
      "Epoch: 707\tLoss: 0.029564\n",
      "Epoch: 708\tLoss: 0.029550\n",
      "Epoch: 709\tLoss: 0.029536\n",
      "Epoch: 710\tLoss: 0.029521\n",
      "Epoch: 711\tLoss: 0.029507\n",
      "Epoch: 712\tLoss: 0.029493\n",
      "Epoch: 713\tLoss: 0.029478\n",
      "Epoch: 714\tLoss: 0.029464\n",
      "Epoch: 715\tLoss: 0.029450\n",
      "Epoch: 716\tLoss: 0.029435\n",
      "Epoch: 717\tLoss: 0.029421\n",
      "Epoch: 718\tLoss: 0.029406\n",
      "Epoch: 719\tLoss: 0.029392\n",
      "Epoch: 720\tLoss: 0.029378\n",
      "Epoch: 721\tLoss: 0.029363\n",
      "Epoch: 722\tLoss: 0.029349\n",
      "Epoch: 723\tLoss: 0.029334\n",
      "Epoch: 724\tLoss: 0.029320\n",
      "Epoch: 725\tLoss: 0.029306\n",
      "Epoch: 726\tLoss: 0.029291\n",
      "Epoch: 727\tLoss: 0.029277\n",
      "Epoch: 728\tLoss: 0.029263\n",
      "Epoch: 729\tLoss: 0.029248\n",
      "Epoch: 730\tLoss: 0.029234\n",
      "Epoch: 731\tLoss: 0.029220\n",
      "Epoch: 732\tLoss: 0.029205\n",
      "Epoch: 733\tLoss: 0.029191\n",
      "Epoch: 734\tLoss: 0.029177\n",
      "Epoch: 735\tLoss: 0.029163\n",
      "Epoch: 736\tLoss: 0.029148\n",
      "Epoch: 737\tLoss: 0.029134\n",
      "Epoch: 738\tLoss: 0.029120\n",
      "Epoch: 739\tLoss: 0.029105\n",
      "Epoch: 740\tLoss: 0.029091\n",
      "Epoch: 741\tLoss: 0.029077\n",
      "Epoch: 742\tLoss: 0.029062\n",
      "Epoch: 743\tLoss: 0.029048\n",
      "Epoch: 744\tLoss: 0.029034\n",
      "Epoch: 745\tLoss: 0.029019\n",
      "Epoch: 746\tLoss: 0.029005\n",
      "Epoch: 747\tLoss: 0.028991\n",
      "Epoch: 748\tLoss: 0.028976\n",
      "Epoch: 749\tLoss: 0.028962\n",
      "Epoch: 750\tLoss: 0.028947\n",
      "Epoch: 751\tLoss: 0.028933\n",
      "Epoch: 752\tLoss: 0.028919\n",
      "Epoch: 753\tLoss: 0.028904\n",
      "Epoch: 754\tLoss: 0.028890\n",
      "Epoch: 755\tLoss: 0.028875\n",
      "Epoch: 756\tLoss: 0.028861\n",
      "Epoch: 757\tLoss: 0.028847\n",
      "Epoch: 758\tLoss: 0.028833\n",
      "Epoch: 759\tLoss: 0.028818\n",
      "Epoch: 760\tLoss: 0.028804\n",
      "Epoch: 761\tLoss: 0.028790\n",
      "Epoch: 762\tLoss: 0.028775\n",
      "Epoch: 763\tLoss: 0.028760\n",
      "Epoch: 764\tLoss: 0.028746\n",
      "Epoch: 765\tLoss: 0.028731\n",
      "Epoch: 766\tLoss: 0.028717\n",
      "Epoch: 767\tLoss: 0.028703\n",
      "Epoch: 768\tLoss: 0.028688\n",
      "Epoch: 769\tLoss: 0.028674\n",
      "Epoch: 770\tLoss: 0.028660\n",
      "Epoch: 771\tLoss: 0.028645\n",
      "Epoch: 772\tLoss: 0.028631\n",
      "Epoch: 773\tLoss: 0.028617\n",
      "Epoch: 774\tLoss: 0.028602\n",
      "Epoch: 775\tLoss: 0.028588\n",
      "Epoch: 776\tLoss: 0.028574\n",
      "Epoch: 777\tLoss: 0.028560\n",
      "Epoch: 778\tLoss: 0.028545\n",
      "Epoch: 779\tLoss: 0.028531\n",
      "Epoch: 780\tLoss: 0.028517\n",
      "Epoch: 781\tLoss: 0.028503\n",
      "Epoch: 782\tLoss: 0.028489\n",
      "Epoch: 783\tLoss: 0.028474\n",
      "Epoch: 784\tLoss: 0.028460\n",
      "Epoch: 785\tLoss: 0.028446\n",
      "Epoch: 786\tLoss: 0.028432\n",
      "Epoch: 787\tLoss: 0.028418\n",
      "Epoch: 788\tLoss: 0.028403\n",
      "Epoch: 789\tLoss: 0.028389\n",
      "Epoch: 790\tLoss: 0.028375\n",
      "Epoch: 791\tLoss: 0.028360\n",
      "Epoch: 792\tLoss: 0.028346\n",
      "Epoch: 793\tLoss: 0.028332\n",
      "Epoch: 794\tLoss: 0.028317\n",
      "Epoch: 795\tLoss: 0.028303\n",
      "Epoch: 796\tLoss: 0.028289\n",
      "Epoch: 797\tLoss: 0.028275\n",
      "Epoch: 798\tLoss: 0.028260\n",
      "Epoch: 799\tLoss: 0.028246\n",
      "Epoch: 800\tLoss: 0.028232\n",
      "Epoch: 801\tLoss: 0.028217\n",
      "Epoch: 802\tLoss: 0.028203\n",
      "Epoch: 803\tLoss: 0.028189\n",
      "Epoch: 804\tLoss: 0.028174\n",
      "Epoch: 805\tLoss: 0.028160\n",
      "Epoch: 806\tLoss: 0.028146\n",
      "Epoch: 807\tLoss: 0.028132\n",
      "Epoch: 808\tLoss: 0.028117\n",
      "Epoch: 809\tLoss: 0.028103\n",
      "Epoch: 810\tLoss: 0.028089\n",
      "Epoch: 811\tLoss: 0.028075\n",
      "Epoch: 812\tLoss: 0.028060\n",
      "Epoch: 813\tLoss: 0.028046\n",
      "Epoch: 814\tLoss: 0.028032\n",
      "Epoch: 815\tLoss: 0.028018\n",
      "Epoch: 816\tLoss: 0.028003\n",
      "Epoch: 817\tLoss: 0.027989\n",
      "Epoch: 818\tLoss: 0.027975\n",
      "Epoch: 819\tLoss: 0.027961\n",
      "Epoch: 820\tLoss: 0.027946\n",
      "Epoch: 821\tLoss: 0.027932\n",
      "Epoch: 822\tLoss: 0.027918\n",
      "Epoch: 823\tLoss: 0.027904\n",
      "Epoch: 824\tLoss: 0.027889\n",
      "Epoch: 825\tLoss: 0.027875\n",
      "Epoch: 826\tLoss: 0.027861\n",
      "Epoch: 827\tLoss: 0.027846\n",
      "Epoch: 828\tLoss: 0.027832\n",
      "Epoch: 829\tLoss: 0.027817\n",
      "Epoch: 830\tLoss: 0.027803\n",
      "Epoch: 831\tLoss: 0.027788\n",
      "Epoch: 832\tLoss: 0.027774\n",
      "Epoch: 833\tLoss: 0.027760\n",
      "Epoch: 834\tLoss: 0.027745\n",
      "Epoch: 835\tLoss: 0.027731\n",
      "Epoch: 836\tLoss: 0.027717\n",
      "Epoch: 837\tLoss: 0.027702\n",
      "Epoch: 838\tLoss: 0.027688\n",
      "Epoch: 839\tLoss: 0.027674\n",
      "Epoch: 840\tLoss: 0.027659\n",
      "Epoch: 841\tLoss: 0.027645\n",
      "Epoch: 842\tLoss: 0.027631\n",
      "Epoch: 843\tLoss: 0.027616\n",
      "Epoch: 844\tLoss: 0.027602\n",
      "Epoch: 845\tLoss: 0.027588\n",
      "Epoch: 846\tLoss: 0.027573\n",
      "Epoch: 847\tLoss: 0.027559\n",
      "Epoch: 848\tLoss: 0.027545\n",
      "Epoch: 849\tLoss: 0.027531\n",
      "Epoch: 850\tLoss: 0.027516\n",
      "Epoch: 851\tLoss: 0.027502\n",
      "Epoch: 852\tLoss: 0.027488\n",
      "Epoch: 853\tLoss: 0.027474\n",
      "Epoch: 854\tLoss: 0.027459\n",
      "Epoch: 855\tLoss: 0.027445\n",
      "Epoch: 856\tLoss: 0.027431\n",
      "Epoch: 857\tLoss: 0.027417\n",
      "Epoch: 858\tLoss: 0.027402\n",
      "Epoch: 859\tLoss: 0.027388\n",
      "Epoch: 860\tLoss: 0.027374\n",
      "Epoch: 861\tLoss: 0.027360\n",
      "Epoch: 862\tLoss: 0.027346\n",
      "Epoch: 863\tLoss: 0.027331\n",
      "Epoch: 864\tLoss: 0.027317\n",
      "Epoch: 865\tLoss: 0.027303\n",
      "Epoch: 866\tLoss: 0.027289\n",
      "Epoch: 867\tLoss: 0.027275\n",
      "Epoch: 868\tLoss: 0.027260\n",
      "Epoch: 869\tLoss: 0.027246\n",
      "Epoch: 870\tLoss: 0.027232\n",
      "Epoch: 871\tLoss: 0.027218\n",
      "Epoch: 872\tLoss: 0.027204\n",
      "Epoch: 873\tLoss: 0.027189\n",
      "Epoch: 874\tLoss: 0.027175\n",
      "Epoch: 875\tLoss: 0.027161\n",
      "Epoch: 876\tLoss: 0.027147\n",
      "Epoch: 877\tLoss: 0.027132\n",
      "Epoch: 878\tLoss: 0.027118\n",
      "Epoch: 879\tLoss: 0.027104\n",
      "Epoch: 880\tLoss: 0.027090\n",
      "Epoch: 881\tLoss: 0.027075\n",
      "Epoch: 882\tLoss: 0.027061\n",
      "Epoch: 883\tLoss: 0.027047\n",
      "Epoch: 884\tLoss: 0.027033\n",
      "Epoch: 885\tLoss: 0.027018\n",
      "Epoch: 886\tLoss: 0.027004\n",
      "Epoch: 887\tLoss: 0.026990\n",
      "Epoch: 888\tLoss: 0.026976\n",
      "Epoch: 889\tLoss: 0.026961\n",
      "Epoch: 890\tLoss: 0.026947\n",
      "Epoch: 891\tLoss: 0.026933\n",
      "Epoch: 892\tLoss: 0.026918\n",
      "Epoch: 893\tLoss: 0.026904\n",
      "Epoch: 894\tLoss: 0.026890\n",
      "Epoch: 895\tLoss: 0.026876\n",
      "Epoch: 896\tLoss: 0.026861\n",
      "Epoch: 897\tLoss: 0.026847\n",
      "Epoch: 898\tLoss: 0.026833\n",
      "Epoch: 899\tLoss: 0.026818\n",
      "Epoch: 900\tLoss: 0.026804\n",
      "Epoch: 901\tLoss: 0.026790\n",
      "Epoch: 902\tLoss: 0.026776\n",
      "Epoch: 903\tLoss: 0.026761\n",
      "Epoch: 904\tLoss: 0.026747\n",
      "Epoch: 905\tLoss: 0.026733\n",
      "Epoch: 906\tLoss: 0.026719\n",
      "Epoch: 907\tLoss: 0.026704\n",
      "Epoch: 908\tLoss: 0.026690\n",
      "Epoch: 909\tLoss: 0.026676\n",
      "Epoch: 910\tLoss: 0.026662\n",
      "Epoch: 911\tLoss: 0.026647\n",
      "Epoch: 912\tLoss: 0.026633\n",
      "Epoch: 913\tLoss: 0.026619\n",
      "Epoch: 914\tLoss: 0.026604\n",
      "Epoch: 915\tLoss: 0.026590\n",
      "Epoch: 916\tLoss: 0.026576\n",
      "Epoch: 917\tLoss: 0.026562\n",
      "Epoch: 918\tLoss: 0.026547\n",
      "Epoch: 919\tLoss: 0.026533\n",
      "Epoch: 920\tLoss: 0.026519\n",
      "Epoch: 921\tLoss: 0.026504\n",
      "Epoch: 922\tLoss: 0.026490\n",
      "Epoch: 923\tLoss: 0.026476\n",
      "Epoch: 924\tLoss: 0.026461\n",
      "Epoch: 925\tLoss: 0.026447\n",
      "Epoch: 926\tLoss: 0.026433\n",
      "Epoch: 927\tLoss: 0.026418\n",
      "Epoch: 928\tLoss: 0.026404\n",
      "Epoch: 929\tLoss: 0.026389\n",
      "Epoch: 930\tLoss: 0.026375\n",
      "Epoch: 931\tLoss: 0.026361\n",
      "Epoch: 932\tLoss: 0.026346\n",
      "Epoch: 933\tLoss: 0.026332\n",
      "Epoch: 934\tLoss: 0.026318\n",
      "Epoch: 935\tLoss: 0.026303\n",
      "Epoch: 936\tLoss: 0.026289\n",
      "Epoch: 937\tLoss: 0.026275\n",
      "Epoch: 938\tLoss: 0.026260\n",
      "Epoch: 939\tLoss: 0.026246\n",
      "Epoch: 940\tLoss: 0.026231\n",
      "Epoch: 941\tLoss: 0.026217\n",
      "Epoch: 942\tLoss: 0.026203\n",
      "Epoch: 943\tLoss: 0.026188\n",
      "Epoch: 944\tLoss: 0.026174\n",
      "Epoch: 945\tLoss: 0.026159\n",
      "Epoch: 946\tLoss: 0.026145\n",
      "Epoch: 947\tLoss: 0.026131\n",
      "Epoch: 948\tLoss: 0.026116\n",
      "Epoch: 949\tLoss: 0.026102\n",
      "Epoch: 950\tLoss: 0.026087\n",
      "Epoch: 951\tLoss: 0.026073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 952\tLoss: 0.026058\n",
      "Epoch: 953\tLoss: 0.026044\n",
      "Epoch: 954\tLoss: 0.026029\n",
      "Epoch: 955\tLoss: 0.026015\n",
      "Epoch: 956\tLoss: 0.026000\n",
      "Epoch: 957\tLoss: 0.025986\n",
      "Epoch: 958\tLoss: 0.025971\n",
      "Epoch: 959\tLoss: 0.025957\n",
      "Epoch: 960\tLoss: 0.025942\n",
      "Epoch: 961\tLoss: 0.025928\n",
      "Epoch: 962\tLoss: 0.025913\n",
      "Epoch: 963\tLoss: 0.025899\n",
      "Epoch: 964\tLoss: 0.025884\n",
      "Epoch: 965\tLoss: 0.025870\n",
      "Epoch: 966\tLoss: 0.025855\n",
      "Epoch: 967\tLoss: 0.025840\n",
      "Epoch: 968\tLoss: 0.025826\n",
      "Epoch: 969\tLoss: 0.025811\n",
      "Epoch: 970\tLoss: 0.025797\n",
      "Epoch: 971\tLoss: 0.025782\n",
      "Epoch: 972\tLoss: 0.025768\n",
      "Epoch: 973\tLoss: 0.025753\n",
      "Epoch: 974\tLoss: 0.025738\n",
      "Epoch: 975\tLoss: 0.025724\n",
      "Epoch: 976\tLoss: 0.025709\n",
      "Epoch: 977\tLoss: 0.025694\n",
      "Epoch: 978\tLoss: 0.025680\n",
      "Epoch: 979\tLoss: 0.025665\n",
      "Epoch: 980\tLoss: 0.025651\n",
      "Epoch: 981\tLoss: 0.025636\n",
      "Epoch: 982\tLoss: 0.025621\n",
      "Epoch: 983\tLoss: 0.025606\n",
      "Epoch: 984\tLoss: 0.025592\n",
      "Epoch: 985\tLoss: 0.025577\n",
      "Epoch: 986\tLoss: 0.025562\n",
      "Epoch: 987\tLoss: 0.025547\n",
      "Epoch: 988\tLoss: 0.025532\n",
      "Epoch: 989\tLoss: 0.025518\n",
      "Epoch: 990\tLoss: 0.025503\n",
      "Epoch: 991\tLoss: 0.025488\n",
      "Epoch: 992\tLoss: 0.025473\n",
      "Epoch: 993\tLoss: 0.025458\n",
      "Epoch: 994\tLoss: 0.025443\n",
      "Epoch: 995\tLoss: 0.025428\n",
      "Epoch: 996\tLoss: 0.025413\n",
      "Epoch: 997\tLoss: 0.025398\n",
      "Epoch: 998\tLoss: 0.025383\n",
      "Epoch: 999\tLoss: 0.025368\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "train(model, x_train, y_train, 1000, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_by_model(env, model, cmd):\n",
    "    field_size = env.field.shape[0]\n",
    "    \n",
    "    column = env.action_column(cmd)\n",
    "    # join action_column to field at rigth to make NxN+1 sized numpy array\n",
    "    field_augmented = np.concatenate((env.field, column.reshape(1,field_size).T), axis=1)\n",
    "    # add input data example\n",
    "    x_predict = np.array([field_augmented.reshape(field_size*(field_size+1))])\n",
    "    # reshape NxN+1 to N*(N+1)\n",
    "    # x_predict = np.array([env.field.reshape(field_size**2)])\n",
    "    \n",
    "    # convert to torch format\n",
    "    x_predict = Variable(torch.from_numpy(x_predict).float())\n",
    "    \n",
    "    # send to device\n",
    "    x_predict = x_predict.to(device)\n",
    "    \n",
    "    # predict and copy to cpu\n",
    "    y_predict = model(x_predict).cpu().data.numpy()    \n",
    "    \n",
    "    # reshape to field format\n",
    "    y_predict.reshape(field_size,field_size)\n",
    "    # set max probability to 1\n",
    "    y_predict[np.arange(y_predict.shape[0]), y_predict.argmax(1)] = 1\n",
    "    # set others probabilities to 0\n",
    "    y_predict[y_predict < 1] = 0\n",
    "    # reshape to 5*5 and update field\n",
    "    env.field = y_predict.reshape(field_size, field_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "field_size = 5\n",
    "env = Env(field_size)\n",
    "env.plot()\n",
    "move_by_model(env, model, 'U')\n",
    "env.plot()\n",
    "move_by_model(env, model, 'U')\n",
    "env.plot()\n",
    "move_by_model(env, model, 'U')\n",
    "env.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "move_by_model(env, model, 'R')\n",
    "env.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "move_by_model(env, model, 'D')\n",
    "env.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "move_by_model(env, model, 'L')\n",
    "env.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "move_by_model(env, model, 'L')\n",
    "env.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "move_by_model(env, model, 'L')\n",
    "env.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
